# Word Embeddings

Classifying architectures ,

1. Convolutional Neural Networks
2. Recurrent Neural Networks ( Long-Short Term Memory Cells / LSTMS)
3. Fully Connected Neural Network

Embedding approaches,
1. Continuous Bag Of Words
2. Skip-Gram
3. Count Vector
3. One-Hot encoding
4. FastText (Skip-Gram)..etc

## Model Architectures

![Model Architectures](https://github.com/TejaSreenivas/Word_Embeddings/blob/master/nnarch.png)


